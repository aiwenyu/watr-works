@import Main._

  @p
    Features
    textDensity
    charCountFeature
    lineHeightMaxMeanFeature
    lineHeightMeanFeature
    bibinfoFeature
    charCountRelativeFeature
    commaCountFeature
    commaRelativeCountFeature
    ContainsCuePhrasesFeature
    containsPageNumberFeature
    contributionFeature
    correspondenceFeature
    dotCountFeature
    dotRelativeCountFeature
    figureFeature
    figureTableFeature
    freeSpaceWithinZoneFeature
    greekLettersFeature
    keywordsFeature
    lastButOneZoneFeature
    letterCountFeature
    letterRelativeCountFeature
    licenseFeature
    lineCountFeature
    lineRelativeCountFeature
    lineWidthMeanFeature
    lineXPositionDiffFeature
    lineXPositionMeanFeature
    lineXWidthPositionDiffFeature
    mathSymbolsFeature
    pageNumberFeature
    referencesFeature
    referencesTitleFeature
    relativeMeanLengthFeature
    startsWithDigitFeature
    StartsWithHeaderFeature
    uppercaseCountFeature
    uppercaseRelativeCountFeature
    uppercaseWordCountFeature
    uppercaseWordRelativeCountFeature
    verticalProminenceFeature
    widthFeature
    widthRelativeFeature

  @p
    A few document segmentation problems:

    Spacing in patterns like these:
        cind @nitt.edu
        www.*.*
        Pt/PANi
        [7,17–24]
        10^{5}s^{1}
        doi: 10.1029/2005JD006318
        70^{◦}C
        Fe_{3}O_{4}@C


    - [ ] words parsed as stream of single chars (particularly on line w/one word)
         - 2 0 1 2 J D 0 1 7 45 9 . 1010022013gl058232.pdf.d <target pg:4 (l:319.97, t:560.87, w:50.71, h:7.28)
    - [ ] sup/subs are squished w/adjacent words
    - [ ] ligatures get sup/subscripted
    - [ ] inclusion of technical discipline-specific vocabulary in addition to default dictionary 
    - [ ] common phrase parsing (e.g, "et al." as a single token)
    - [ ] parse footnote sup/sub markers as independent tokens
    - [ ] A few reversed words across entire paper ??!! (I think doc orientation value is incorrect)
    - [ ] Non-textline elimination
    - [ ] better weight/measure/quantity parsing and tokenization
